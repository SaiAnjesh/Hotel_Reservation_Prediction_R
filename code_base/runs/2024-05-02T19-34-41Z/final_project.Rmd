---
title: "Final Project"
author: "Sai Anjesh"
date: "2024-04-16"
output: html_notebook
---

# HOTEL RESERVATION CANCELLATION PREDCITION


```{r}
## Importing Necessary Libraries
##---------
FUNCTIONS_PATH = "D:/UIS/Studies/Semester4/CSC532/Assignments/ML_Final_Project/ml_final_project/code_base/custom_functions.R"
##---------
source(FUNCTIONS_PATH)
##---------
library(dplyr)
library(ROCR)
library(caret)
library(glmnet)
library(randomForest)
library(gbm)
library(keras)
library(tfruns)
library(abind)
library(mltools)
library(data.table)
##---------
```


```{r}
# I am creating this to save models
# Most of the models take time to run
# Can uuse these model objects later during the process

# CHAT_GPT Assistance: how to create folder if it does not exist in R?
# Specify the path to the folder you want to create
models_folder_path <- "D:/UIS/Studies/Semester4/CSC532/Assignments/ML_Final_Project/ml_final_project/ALL_MODELS"
# over_write_models <- T
over_write_models <- F

# Check if the folder exists
if (!file.exists(models_folder_path)) {
  # If the folder does not exist, create it
  dir.create(models_folder_path)
  cat("Folder created successfully!\n")
} else {
  cat("Folder already exists!\n")
}
```


#### Let us import dataset

```{r}
## File Paths
input_folder_path = "D:/UIS/Studies/Semester4/CSC532/Assignments/ML_Final_Project/ml_final_project/input_datasets/"
input_file_name = "hotel_reservations_dataset/Hotel Reservations.csv"
hotel_reservation_data = paste(input_folder_path, input_file_name, sep = "")
```

```{r}
hotel_reservation_data <- read.csv(file = hotel_reservation_data, header = TRUE)
```

#### Let us check some basic information

```{r}
## Primitive Information
# Let us check the shape of the data
print(paste("Number of Records : ", dim(hotel_reservation_data)[1]))
print(paste("Number of Features : ", dim(hotel_reservation_data)[2]))

# Let us check the feature name snad the structure
str(hotel_reservation_data)

# Check the summary
summary(hotel_reservation_data)
```



##### Let us check the NA values

```{r}
# Let us check the NA cases
# Check if there are missing values
# And let us do a thorough check
sum(is.na(hotel_reservation_data))
colSums(is.na(hotel_reservation_data))

# Check 1
na_records <- hotel_reservation_data[!complete.cases(hotel_reservation_data), ]
```


Fortunately we don't have NA values, we shall continue to transform the structure.

#### Let us convert the struture of the dataframe
```{r}
# Check the str
str(hotel_reservation_data)

categorized_features <- categorize_features(hotel_reservation_data)
# Checking the column names
cat("Numeric columns: \n------\n", paste(categorized_features$numeric_cols, collapse = ", "), "\n")
cat("Factor columns: \n------\n", paste(categorized_features$factor_cols, collapse = ", "), "\n")
cat("Character columns: \n------\n", paste(categorized_features$character_cols, collapse = ", "),"\n")
```
```{r}
# # Let us check the character variables and understand the unique values
# for(col_val in categorized_features$character_cols) {
#   cat(paste("-----", col_val, "-----\n", sep = ""))
#   cat(paste(sort(unique(hotel_reservation_data[[col_val]]), decreasing = F), collapse = ", "), "\n")
# }

```


```{r}
# Removing the first Column 
# Jsut a unique identifier
hotel_reservation_data$Booking_ID <- NULL

# Final OutCome column - Modified
# I We are chaging hte outcome variable, for simplfied understanding of the model and data
hotel_reservation_data$booking_cancellation <- ifelse((hotel_reservation_data$booking_status == "Canceled"), "yes", "no")
hotel_reservation_data$booking_cancellation <- factor(hotel_reservation_data$booking_cancellation)
hotel_reservation_data$booking_status <- NULL

hotel_reservation_data$market_segment_type <- factor(hotel_reservation_data$market_segment_type)
hotel_reservation_data$type_of_meal_plan <- factor(hotel_reservation_data$type_of_meal_plan)
hotel_reservation_data$room_type_reserved <- factor(hotel_reservation_data$room_type_reserved)

# Since these are just variables
# We are going to give life to it by assigneing various room types
# CREDITS: https://hoteltechreport.com/news/room-type


# c("Room_Type 1", "Room_Type 2", "Room_Type 3", "Room_Type 4", "Room_Type 5", "Room_Type 6", "Room_Type 7")
# # c("standard_room", "deluxe_room", "joint_room", "connecting_room", "suite_room", "apartment_style_room", "accessible_room")


```



```{r}
# Check the str
str(hotel_reservation_data)

categorized_features <- categorize_features(hotel_reservation_data)
# Checking the column names
cat("Numeric columns: \n------\n", paste(categorized_features$numeric_cols, collapse = ", "), "\n")
cat("Factor columns: \n------\n", paste(categorized_features$factor_cols, collapse = ", "), "\n")
cat("Character columns: \n------\n", paste(categorized_features$character_cols, collapse = ", "),"\n")
```

## NOTE: WE HAVE SKIPPED THE EDA PART....WE WILL HAVE TO COMPLETE IT


#### Let us get started with the modeling

```{r}
# Let us check the class blance
prop.table(table(hotel_reservation_data$booking_cancellation))
```
From the above classes table we can surely say that the 

```{r}
# Let us bacup saiing a data
hotel_reservation_data_processed_bkup <- hotel_reservation_data
```


```{r}
# Let us split the data into train and test
# We are using 90% train and 10% test
# We have over 30K reords
train_index <- createDataPartition(y = hotel_reservation_data$booking_cancellation, p = 0.9, list = FALSE)
hotel_reservation_data_train <- hotel_reservation_data[train_index, ]
hotel_reservation_data_test <- hotel_reservation_data[-train_index, ]
```


```{r}
# Let us determiine the class weights
class_weights_values <- class_weight_determination_fn(output_var = hotel_reservation_data_train$booking_cancellation)
class_weights_vector <- ifelse(hotel_reservation_data_train$booking_cancellation == "yes", 
                               class_weights_values$weight_yes, class_weights_values$weight_no)

```



```{r}
# Variable to contain the list of models
MODEL_LIST <- list()

# Control Variables
MODEL_K_FOLDS <- 10
MODEL_CONTROL_METHOD <- "cv"
# MODEL_TRAIN_METHOD <- "gbm"
MODEL_METRIC <- "ROC"
MODEL_TRAIN_DATA <- hotel_reservation_data_train
MODEL_TEST_DATA <- hotel_reservation_data_test
MODEL_DV_VAR <- "booking_cancellation"
##-------
ALPHA_VALUE = list(
  LASSO = 1,
  RIDGE = 0,
  ELASTIC = seq(0, 1, length = 10)
)
LAMBDA_GRID <- 10^seq(-3, 3, length = 100)
``` 




```{r}
# First model
if(over_write_models) {
  print("Running Model...")
  
  set.seed(1)
  control_values <- trainControl(method = MODEL_CONTROL_METHOD, 
                                 number = MODEL_K_FOLDS, 
                                 classProbs = TRUE, 
                                 summaryFunction = twoClassSummary)
  
  m_weighted_gbm <- train(booking_cancellation ~ ., 
                          data = MODEL_TRAIN_DATA, 
                          method = "gbm", 
                          weights = class_weights_vector,
                          verbose = TRUE,
                          # verbose = FALSE, 
                          metric = MODEL_METRIC, 
                          trControl = control_values)
  print(m_weighted_gbm)
  
  # Savig the model objects for future use
  MODEL_NAME <- "GRADIENT_BOOST"; MODEL_LIST[[MODEL_NAME]] <- m_weighted_gbm;
  saveRDS(MODEL_LIST[[MODEL_NAME]], file = paste(models_folder_path,"/", MODEL_NAME,"_MODEL.rds",sep = ""))
}

```


```{r}
if(over_write_models) {
  print("Running Model...")
  
  set.seed(1)

  LASSO_MODEL <- train(booking_cancellation ~.,
                       data = MODEL_TRAIN_DATA,
                       method = "glmnet",
                       metric = MODEL_METRIC,
                       trControl = control_values,
                       tuneGrid = expand.grid(alpha = ALPHA_VALUE$LASSO, lambda = LAMBDA_GRID),
                       verboseIter = TRUE,
                       verbose = TRUE)
  
  # print(LASSO_MODEL)
  # print(coef(LASSO_MODEL$finalModel, LASSO_MODEL$bestTune$lambda))
  
  # Savig the model objects for future use
  MODEL_NAME <- "LASSO_LOGISTIC"; MODEL_LIST[[MODEL_NAME]] <- LASSO_MODEL;
  saveRDS(MODEL_LIST[[MODEL_NAME]], file = paste(models_folder_path,"/", MODEL_NAME,"_MODEL.rds",sep = ""))
}

```

```{r}
# gbm_predictions_prob = predict(m_weighted_gbm, MODEL_TEST_DATA, type="prob")
# gbm_predictions = prediction(predictions = gbm_predictions_prob$yes, MODEL_TEST_DATA$booking_cancellation)
# 
# performance(gbm_predictions, measure = "auc")@y.values
# 
# gbm_predicted_labels = predict(m_weighted_gbm, MODEL_TEST_DATA)
# confusionMatrix(gbm_predicted_labels, MODEL_TEST_DATA$booking_cancellation, positive="yes", mode="everything")
```


```{r}
# Models_List

```


```{r}
# Pausing ----
# # Models Evaluation
# for(model_select in names(MODEL_LIST)) {
#   cat(paste("####-----",model_select,"-----####\n", sep = ""))
#   print(classification_evaluation_fn(model_selected_var = MODEL_LIST[[model_select]], 
#                                    test_data_selected = MODEL_TEST_DATA,
#                                    focus_outcome = MODEL_DV_VAR))
# }
# print(classification_evaluation_fn(model_selected_var = m_weighted_gbm,
#                                    test_data_selected = MODEL_TEST_DATA,
#                                    focus_outcome = MODEL_DV_VAR))

```

#### Let us construct the NN for this model
```{r}
# Let us first perfrorm necessary transformation
# Let us first row bind both the train and test dataframe and do one hot encoding
# This 

hotel_reservation_data_train_bkup <- hotel_reservation_data_train
hotel_reservation_data_train_bkup$training_sample <- 1

hotel_reservation_data_test_bkup <- hotel_reservation_data_test
hotel_reservation_data_test_bkup$training_sample <- 0

# Concategnate the dataframes
hotel_reservation_data_combined_1 <- hotel_reservation_data_train_bkup %>% bind_rows(hotel_reservation_data_test_bkup)
rm(hotel_reservation_data_train_bkup, hotel_reservation_data_test_bkup)

# let usf first check the columns for one hot encoding
columns_for_one_hot_encoding <- categorize_features(hotel_reservation_data_combined_1)$factor_cols
columns_for_one_hot_encoding <- setdiff(columns_for_one_hot_encoding, MODEL_DV_VAR)

# Calling custom made one hot One HOt Enccoding 
hotel_reservation_data_combined_2 <- one_hot_encoding_fn(data_val = hotel_reservation_data_combined_1,
                                                         features_to_encode = columns_for_one_hot_encoding)

# Transforming the outcome variable
# Take care of this variable toawrds the end, when you are predicting the outcom based on the model
hotel_reservation_data_combined_2$booking_cancellation <- (
  as.numeric(hotel_reservation_data_combined_2$booking_cancellation) - 1)

# hotel_reservation_data_combined_2[[MODEL_DV_VAR]] <- ifelse(
#   hotel_reservation_data_combined_2[[MODEL_DV_VAR]] == "yes", TRUE, 
#   ifelse(hotel_reservation_data_combined_2[[MODEL_DV_VAR]] == "no", FALSE,
#          hotel_reservation_data_combined_2[[MODEL_DV_VAR]]))


str(hotel_reservation_data_combined_2)
```


```{r}
# Let us now break the newly updated data into train, test and train into train and validation
hotel_reservation_data_NN_train <- (hotel_reservation_data_combined_2 %>% 
                                      filter(training_sample == 1) %>% 
                                      select(-all_of("training_sample")))
hotel_reservation_data_NN_test <- (hotel_reservation_data_combined_2 %>% 
                                     filter(training_sample == 0) %>% 
                                     select(-all_of("training_sample")))

# Removing this column from the combined datasets
hotel_reservation_data_combined_3 <- hotel_reservation_data_combined_1
hotel_reservation_data_combined_2 <- hotel_reservation_data_combined_2 %>% select(-all_of("training_sample"))
hotel_reservation_data_combined_1 <- hotel_reservation_data_combined_1 %>% select(-all_of("training_sample"))

```

```{r}
# Let us split the train data to train and validation data set
inTrainVal = createDataPartition(hotel_reservation_data_NN_train$booking_cancellation, p=0.9, list=FALSE) 
hotel_reservation_data_NN_train_val   = hotel_reservation_data_NN_train[-inTrainVal,]
hotel_reservation_data_NN_train_train = hotel_reservation_data_NN_train[inTrainVal,]
```


```{r}
# Let us scale the numerical variables
numerical_cols_to_scale <- categorize_features(hotel_reservation_data_combined_1)$numeric_cols
# hotel_reservation_data_combined_1[, numerical_cols_to_scale]

data_train = hotel_reservation_data_NN_train_train
data_val = hotel_reservation_data_NN_train_val
data_test = hotel_reservation_data_NN_test

numerical_features = numerical_cols_to_scale

# Scaling the features
data_train <- data_train %>%  mutate_at(vars(numerical_features), as.numeric)

# Reusig code form the lectures
scaled_data_train <- scale(data_train[, numerical_features])

col_means_train <- attr(scaled_data_train, "scaled:center")
col_stddevs_train <- attr(scaled_data_train, "scaled:scale")

scaled_data_test <- scale(data_test[, numerical_features], center = col_means_train, scale = col_stddevs_train)

scaled_data_val <- scale(data_val[, numerical_features], center = col_means_train, scale = col_stddevs_train)

# Re arragning the features in all the datasets
# Using the train scaling feauters to avoid data leakage
data_train <- cbind(scaled_data_train, data_train[, !(colnames(data_train) %in% numerical_features)])
data_test <- cbind(scaled_data_test, data_test[, !(colnames(data_test) %in% numerical_features)])
data_val <- cbind(scaled_data_val, data_val[, !(colnames(data_val) %in% numerical_features)])

# Returing the data
# Will construct this into a function in fututre project
hotel_reservation_data_NN_train_train = data_train
hotel_reservation_data_NN_train_val = data_val
hotel_reservation_data_NN_test = data_test
```


```{r}
# Dissecting the IDVs and DVs
train_IDV <- as.matrix(hotel_reservation_data_NN_train_train %>% select(-one_of(c(MODEL_DV_VAR))))
train_DV <- (hotel_reservation_data_NN_train_train[, MODEL_DV_VAR])

test_IDV <- as.matrix(hotel_reservation_data_NN_test %>% select(-one_of(c(MODEL_DV_VAR))))
test_DV <- as.matrix(hotel_reservation_data_NN_test[, MODEL_DV_VAR])

val_IDV <- as.matrix(hotel_reservation_data_NN_train_val %>% select(-one_of(c(MODEL_DV_VAR))))
val_DV <- hotel_reservation_data_NN_train_val[, MODEL_DV_VAR]
```

#### Let us create a simple model first and move on to construcutig tuned model

```{r}
set.seed(1)

# Simple Model
simple_model <- (
  keras_model_sequential() %>%
    layer_dense(units = 16, activation = "sigmoid", input_shape = dim(train_IDV)[2]) %>%
    layer_dropout(rate = 0.1) %>%
    layer_dense(units = 16, activation = "sigmoid") %>%
    layer_dropout(rate = 0.1) %>%
    layer_dense(units =  1, activation = "sigmoid")
)

simple_model %>% compile(optimizer = optimizer_adam(learning_rate = 0.01),
                         loss = 'binary_crossentropy',
                         metrics = c('accuracy'))

# Checkign the model structure
print(simple_model)

# Trainging the model
history <- simple_model %>% fit(
  x = train_IDV,
  y = train_DV,
  epochs = 10,
  batch_size = 16, 
  validation_data = list(val_IDV, val_DV),
  class_weight = list("0" = class_weights_values$weight_no, "1" = class_weights_values$weight_yes),
  verbose = 1
)

history

plot(history)

# Prediction
predicted_labels <- as.numeric(simple_model %>% predict(test_IDV) %>% k_argmax())
cross_table <- table(Actual_Labels = test_DV, Predicted_Labels = predicted_labels)
print(cross_table)


```

The above model does not seem to satify our expectations, so let us contruct a better neural network model.

```{r}
# Performing multiple TF runs
# Just using small values
# Running it on my local machine
tuning_path = "D:/UIS/Studies/Semester4/CSC532/Assignments/ML_Final_Project/ml_final_project/code_base/final_project_tuning.R"
# nodes_list = c(64, 128, 256, 392, 512, 1024)
nodes_list = c(8)
learning_rates_list = c(0.01, 0.05, 0.001)#, 0.005)
# batch_size_list = c(16, 32, 64, 128)
batch_size_list = c(8)
activations_list = c( "sigmoid")#,  "relu", "tanh")
sample_perc = 0.01

# Performing tUNED NN
runs <- tuning_run(tuning_path,
                   flags = list(
                     nodes = nodes_list,
                     learning_rate = learning_rates_list,
                     batch_size = batch_size_list,
                     activation = activations_list
                     ),
                   sample = sample_perc)
```



```{r}
# Extracting the TF run information
# Sorting based on the metric loss
runs <- runs[order(runs$metric_val_loss, decreasing = FALSE),]
as.data.frame(runs)
```

```{r}
# Let’s view the summary of the best run
view_run(runs$run_dir[1]) 
```

```{r}
# Saving runs for future use
class(runs)
runs_save_file_path = "D:/UIS/Studies/Semester4/CSC532/Assignments/Assignment5/regularization_ensemble_project/code_base/All Models Folder/"
runs_save_file_name = paste("NN_RUNS_", format(Sys.time(), "%Y%m%d_%H%M"), ".csv", sep = "")
runs_save_file_name = paste(runs_save_file_path, runs_save_file_name, sep = "")
write.csv(runs, file = runs_save_file_name, row.names = FALSE)
print(paste(runs_save_file_name, " - file saved"))
```
